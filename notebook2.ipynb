{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af73fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolact' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Downloads/Robotic/T5.2/onebook/yolact\n",
      "Requirement already satisfied: torch in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (0.23.0+cu128)\n",
      "Requirement already satisfied: filelock in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from triton==3.4.0->torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: Pillow in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (11.3.0)\n",
      "Requirement already satisfied: pycocotools in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (2.0.10)\n",
      "Requirement already satisfied: matplotlib in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from opencv-python) (2.2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/Downloads/venv/myvenv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Clone the official YOLACT repository\n",
    "!git clone https://github.com/dbolya/yolact.git\n",
    "%cd yolact\n",
    "\n",
    "# Install required packages\n",
    "!pip install torch torchvision\n",
    "!pip install opencv-python Pillow pycocotools matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b26bb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data.config import Config\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_base = Config({\n",
    "    'name': 'My Dataset',\n",
    "\n",
    "    # Training images and annotations   \n",
    "    'train_images': '../my_dataset/train',\n",
    "    'train_info':   '../my_dataset/train/_annotations.coco.json',\n",
    "    \n",
    "    # Validation images and annotations\n",
    "    'valid_images': '../my_dataset/valid',\n",
    "    'valid_info':   '../my_dataset/valid/_annotations.coco.json',\n",
    "\n",
    "    # Define class names list directly inside the config.\n",
    "    'class_names': ('bench', 'chair', 'couch', 'dining table', 'laptop', 'person'),\n",
    "\n",
    "    'has_gt': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419c8d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration is set.\n"
     ]
    }
   ],
   "source": [
    "# The base YOLACT configuration\n",
    "from data.config import yolact_base_config as base_config\n",
    "\n",
    "# Create custom config by overriding the base config\n",
    "yolact_my_config = base_config.copy({\n",
    "    'name': 'yolact_custom',\n",
    "    \n",
    "    # Add dataset config\n",
    "    'dataset': dataset_base,\n",
    "    \n",
    "    # The number of classes classes + 1 for the background.\n",
    "    # this is 6 + 1 = 7.\n",
    "    'num_classes': len(dataset_base.class_names) + 1,\n",
    "\n",
    "    # You can change this to a lower number for faster training, but will result in a less accurate model.\n",
    "    # The default is 800000. \n",
    "    # 'max_iter': 10000,\n",
    "    'max_iter': 200,\n",
    "    \n",
    "    # Decrease the learning rate decay steps to fit the new max_iter\n",
    "    # 'lr_steps': (5000, 8000, 9000),\n",
    "    'lr_steps': (120, 160, 180),\n",
    "\n",
    "    # Do not use an FPN (Feature Pyramid Network) for a very small dataset\n",
    "    # 'fpn': None,\n",
    "})\n",
    "\n",
    "# This registers config and makes it active\n",
    "cfg = yolact_my_config\n",
    "def set_cfg(config_name:str):\n",
    "    global cfg\n",
    "    cfg.replace(config_name)\n",
    "\n",
    "set_cfg(yolact_my_config)\n",
    "print(\"Configuration is set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b94a50",
   "metadata": {},
   "source": [
    "### For CPU environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be6ef84",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m timer\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiBoxLoss\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myolact\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Yolact\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Robotic/T5.2/onebook/yolact/yolact.py:22\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MovingAverage, make_net\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# This is required for Pytorch 1.0.1 on Windows to initialize Cuda on some driver versions.\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# See the bug report here: https://github.com/pytorch/pytorch/issues/17108\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# As of March 10, 2019, Pytorch DataParallel still doesn't support JIT Script Modules\u001b[39;00m\n\u001b[32m     25\u001b[39m use_jit = torch.cuda.device_count() <= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/venv/myvenv/lib/python3.11/site-packages/torch/cuda/__init__.py:1071\u001b[39m, in \u001b[36mcurrent_device\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcurrent_device\u001b[39m() -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   1070\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1071\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1072\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._cuda_getDevice()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/venv/myvenv/lib/python3.11/site-packages/torch/cuda/__init__.py:412\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m    411\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_MODULE_LOADING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mLAZY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    416\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# This cell contains all the necessary functions and classes from the original scripts,\n",
    "# adapted to run in a notebook and on a CPU.\n",
    "\n",
    "# Imports from the YOLACT project\n",
    "from data import *\n",
    "from utils.augmentations import SSDAugmentation, BaseTransform\n",
    "from utils.functions import MovingAverage, SavePath\n",
    "from utils.logger import Log\n",
    "from utils import timer\n",
    "from layers.modules import MultiBoxLoss\n",
    "from yolact import Yolact\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math, random\n",
    "from pathlib import Path\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import datetime\n",
    "import eval as eval_script # Import the original eval script\n",
    "\n",
    "# A simple class to mimic the command-line arguments\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 4 # Lowered for CPU training on a notebook\n",
    "        self.resume = None\n",
    "        self.start_iter = -1\n",
    "        self.num_workers = 0 # Use 0 for workers on Windows/Jupyter, or 2-4 on Linux\n",
    "        self.cuda = False # The key setting for CPU-only\n",
    "        self.lr = 1e-3\n",
    "        self.momentum = 0.9\n",
    "        self.decay = 5e-4\n",
    "        self.gamma = 0.1\n",
    "        self.save_folder = 'weights/'\n",
    "        self.log_folder = 'logs/'\n",
    "        self.config = None # We set this manually above\n",
    "        self.save_interval = 2000\n",
    "        self.validation_size = 5000\n",
    "        self.validation_epoch = 2\n",
    "        self.keep_latest = True\n",
    "        self.keep_latest_interval = 10000\n",
    "        self.dataset = None\n",
    "        self.log = True\n",
    "        self.log_gpu = False\n",
    "        self.interrupt = True\n",
    "        self.batch_alloc = None\n",
    "        self.autoscale = False # Disable autoscale since we are setting params manually\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Set the current learning rate\n",
    "cur_lr = args.lr\n",
    "\n",
    "# Set the default tensor type\n",
    "if args.cuda and torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "# The loss function wrapper from train.py\n",
    "class NetLoss(nn.Module):\n",
    "    def __init__(self, net:Yolact, criterion:MultiBoxLoss):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.criterion = criterion\n",
    "    \n",
    "    def forward(self, images, targets, masks, num_crowds):\n",
    "        preds = self.net(images)\n",
    "        losses = self.criterion(self.net, preds, targets, masks, num_crowds)\n",
    "        return losses\n",
    "\n",
    "# Function to set learning rate\n",
    "def set_lr(optimizer, new_lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "    global cur_lr\n",
    "    cur_lr = new_lr\n",
    "\n",
    "# This is the corrected setup_eval function from train.py\n",
    "def setup_eval():\n",
    "    eval_args = ['--no_bar', '--max_images=' + str(args.validation_size)]\n",
    "    if not args.cuda:\n",
    "        eval_args.append('--cuda=False')\n",
    "    eval_script.parse_args(eval_args)\n",
    "\n",
    "# This is the corrected compute_validation_map function from train.py\n",
    "def compute_validation_map(epoch, iteration, yolact_net, dataset, log:Log=None):\n",
    "    with torch.no_grad():\n",
    "        yolact_net.eval()\n",
    "        start = time.time()\n",
    "        print()\n",
    "        print(\"Computing validation mAP (this may take a while)...\", flush=True)\n",
    "        \n",
    "        # This function will now use the CPU-fixed eval script\n",
    "        val_info = eval_script.evaluate(yolact_net, dataset, train_mode=True)\n",
    "        \n",
    "        end = time.time()\n",
    "        if log is not None:\n",
    "            log.log('val', val_info, elapsed=(end - start), epoch=epoch, iter=iteration)\n",
    "        yolact_net.train()\n",
    "        \n",
    "print(\"Helper functions and classes are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b135f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell monkey-patches the loaded eval_script module to make it CPU-compatible.\n",
    "\n",
    "# --- Fix 1: prep_display ---\n",
    "# The original function has hardcoded .cuda() calls. We replace it with our fixed version.\n",
    "\n",
    "# Grab the original functions from the module so we can still call them\n",
    "original_postprocess = eval_script.postprocess\n",
    "original_undo_image_transformation = eval_script.undo_image_transformation\n",
    "\n",
    "def fixed_prep_display(dets_out, img, h, w, undo_transform=True, class_color=False, mask_alpha=0.45, fps_str=''):\n",
    "    if undo_transform:\n",
    "        img_numpy = original_undo_image_transformation(img, w, h)\n",
    "        display_tensor = torch.Tensor(img_numpy)\n",
    "        if eval_script.args.cuda:\n",
    "            display_tensor = display_tensor.cuda()\n",
    "    else:\n",
    "        display_tensor = torch.Tensor(img) / 255.0\n",
    "        h, w, _ = img.shape\n",
    "        if eval_script.args.cuda:\n",
    "            display_tensor = display_tensor.cuda()\n",
    "\n",
    "    with timer.env('Postprocess'):\n",
    "        save = cfg.rescore_bbox\n",
    "        cfg.rescore_bbox = True\n",
    "        t = original_postprocess(dets_out, w, h, visualize_lincomb = eval_script.args.display_lincomb,\n",
    "                                                 crop_masks        = eval_script.args.crop,\n",
    "                                                 score_threshold   = eval_script.args.score_threshold)\n",
    "        cfg.rescore_bbox = save\n",
    "\n",
    "    with timer.env('Copy'):\n",
    "        idx = t[1].argsort(0, descending=True)[:eval_script.args.top_k]\n",
    "        \n",
    "        if cfg.eval_mask_branch:\n",
    "            masks = t[3][idx]\n",
    "        classes, scores, boxes = [x[idx].cpu().numpy() for x in t[:3]]\n",
    "\n",
    "    num_dets_to_consider = min(eval_script.args.top_k, classes.shape[0])\n",
    "    for j in range(num_dets_to_consider):\n",
    "        if scores[j] < eval_script.args.score_threshold:\n",
    "            num_dets_to_consider = j\n",
    "            break\n",
    "    \n",
    "    def get_color(j, on_gpu=None):\n",
    "        color_idx = (classes[j] * 5 if class_color else j * 5) % len(COLORS)\n",
    "        color = COLORS[color_idx]\n",
    "        if on_gpu is not None:\n",
    "            color = torch.Tensor(color).to(on_gpu).float() / 255.\n",
    "        return color\n",
    "\n",
    "    if eval_script.args.display_masks and cfg.eval_mask_branch and num_dets_to_consider > 0:\n",
    "        masks = masks[:num_dets_to_consider, :, :, None]\n",
    "        colors = torch.cat([get_color(j, on_gpu=display_tensor.device).view(1, 1, 1, 3) for j in range(num_dets_to_consider)], dim=0)\n",
    "        masks_color = masks.repeat(1, 1, 1, 3) * colors * mask_alpha\n",
    "        inv_alph_masks = masks * (-mask_alpha) + 1\n",
    "        \n",
    "        masks_color_summand = masks_color[0]\n",
    "        if num_dets_to_consider > 1:\n",
    "            inv_alph_cumul = inv_alph_masks[:(num_dets_to_consider-1)].cumprod(dim=0)\n",
    "            masks_color_cumul = masks_color[1:] * inv_alph_cumul\n",
    "            masks_color_summand += masks_color_cumul.sum(dim=0)\n",
    "\n",
    "        display_tensor = display_tensor * inv_alph_masks.prod(dim=0) + masks_color_summand\n",
    "    \n",
    "    img_numpy = (display_tensor * 255).byte().cpu().numpy()\n",
    "    \n",
    "    # ... The rest of the drawing logic is fine and uses CPU (cv2) ...\n",
    "    # (The original drawing code from eval.py can be copied here if needed for display)\n",
    "    if num_dets_to_consider > 0:\n",
    "        if eval_script.args.display_text or eval_script.args.display_bboxes:\n",
    "            for j in reversed(range(num_dets_to_consider)):\n",
    "                x1, y1, x2, y2 = boxes[j, :]\n",
    "                color = get_color(j)\n",
    "                score = scores[j]\n",
    "                if eval_script.args.display_bboxes:\n",
    "                    cv2.rectangle(img_numpy, (x1, y1), (x2, y2), color, 1)\n",
    "\n",
    "    return img_numpy\n",
    "\n",
    "\n",
    "# --- Fix 2: prep_metrics ---\n",
    "original_prep_metrics = eval_script.prep_metrics\n",
    "\n",
    "def fixed_prep_metrics(ap_data, dets, img, gt, gt_masks, h, w, num_crowd, image_id, detections:Detections=None):\n",
    "    # This function is complex, so we will call the original but first fix the tensors\n",
    "    # inside `dets` because the original function doesn't handle device placement.\n",
    "    dets = [d.cpu() for d in dets]\n",
    "    return original_prep_metrics(ap_data, dets, img, gt, gt_masks, h, w, num_crowd, image_id, detections)\n",
    "\n",
    "# --- Fix 3: The main evaluate function ---\n",
    "original_evaluate = eval_script.evaluate\n",
    "\n",
    "def fixed_evaluate(net:Yolact, dataset, train_mode=False):\n",
    "    # The original evaluate function has several .cuda() calls.\n",
    "    # We will create a wrapper around it that ensures the network is on the right device.\n",
    "    \n",
    "    net.eval()\n",
    "    if args.cuda:\n",
    "        net = net.cuda()\n",
    "    else:\n",
    "        net = net.cpu() # Explicitly move to CPU\n",
    "\n",
    "    # Now call the original function, but with our CPU-safe network.\n",
    "    # We also need to patch the other functions it calls internally.\n",
    "    eval_script.prep_display = fixed_prep_display\n",
    "    eval_script.prep_metrics = fixed_prep_metrics\n",
    "    \n",
    "    # The original 'evaluate' has its own batch.cuda() call, so we need to patch that.\n",
    "    # Let's do it by wrapping it\n",
    "    def patched_net_call(batch):\n",
    "        if not args.cuda:\n",
    "            batch = batch.cpu()\n",
    "        return net(batch)\n",
    "\n",
    "    # We can't directly patch net() inside evaluate, so this is a bit of a workaround.\n",
    "    # The simplest way is to ensure all tensors are on CPU before they enter the original func.\n",
    "    # Since our fixes in `train.py` handle this, we can proceed.\n",
    "    \n",
    "    return original_evaluate(net, dataset, train_mode)\n",
    "\n",
    "\n",
    "# --- Apply the Patches ---\n",
    "eval_script.evaluate = fixed_evaluate\n",
    "eval_script.prep_display = fixed_prep_display\n",
    "\n",
    "print(\"Monkey-patches for eval.py have been applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f97928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    if not os.path.exists(args.save_folder):\n",
    "        os.mkdir(args.save_folder)\n",
    "\n",
    "    dataset = COCODetection(image_path=cfg.dataset.train_images,\n",
    "                            info_file=cfg.dataset.train_info,\n",
    "                            transform=SSDAugmentation())\n",
    "    \n",
    "    if args.validation_epoch > 0:\n",
    "        setup_eval()\n",
    "        val_dataset = COCODetection(image_path=cfg.dataset.valid_images,\n",
    "                                      info_file=cfg.dataset.valid_info,\n",
    "                                      transform=BaseTransform())\n",
    "\n",
    "    yolact_net = Yolact()\n",
    "    net = yolact_net\n",
    "    net.train()\n",
    "\n",
    "    if args.log:\n",
    "        log = Log(cfg.name, args.log_folder)\n",
    "\n",
    "    if args.resume is not None:\n",
    "        print('Resuming training, loading {}...'.format(args.resume))\n",
    "        yolact_net.load_weights(args.resume)\n",
    "    else:\n",
    "        print('Initializing weights...')\n",
    "        yolact_net.init_weights(backbone_path=args.save_folder + cfg.backbone.path)\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum,\n",
    "                          weight_decay=args.decay)\n",
    "    criterion = MultiBoxLoss(num_classes=cfg.num_classes,\n",
    "                             pos_threshold=cfg.positive_iou_threshold,\n",
    "                             neg_threshold=cfg.negative_iou_threshold,\n",
    "                             negpos_ratio=cfg.ohem_negpos_ratio)\n",
    "\n",
    "    if not args.cuda:\n",
    "        net = NetLoss(net, criterion)\n",
    "    \n",
    "    # ... (the rest of the training setup from train.py)\n",
    "    if not cfg.freeze_bn:\n",
    "        yolact_net.freeze_bn()\n",
    "    \n",
    "    iteration = max(args.start_iter, 0)\n",
    "    last_time = time.time()\n",
    "    epoch_size = len(dataset) // args.batch_size\n",
    "    num_epochs = math.ceil(cfg.max_iter / epoch_size)\n",
    "    step_index = 0\n",
    "\n",
    "    data_loader = data.DataLoader(dataset, args.batch_size,\n",
    "                                  num_workers=args.num_workers,\n",
    "                                  shuffle=True, collate_fn=detection_collate,\n",
    "                                  pin_memory=False) # Pin memory is for GPU\n",
    "    \n",
    "    save_path = lambda epoch, iteration: SavePath(cfg.name, epoch, iteration).get_path(root=args.save_folder)\n",
    "    time_avg = MovingAverage()\n",
    "    loss_types = ['B', 'C', 'M', 'P', 'D', 'E', 'S', 'I']\n",
    "    loss_avgs  = { k: MovingAverage(100) for k in loss_types }\n",
    "\n",
    "    print('Begin training!')\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            for datum in data_loader:\n",
    "                if iteration >= cfg.max_iter:\n",
    "                    break\n",
    "                \n",
    "                while step_index < len(cfg.lr_steps) and iteration >= cfg.lr_steps[step_index]:\n",
    "                    step_index += 1\n",
    "                    set_lr(optimizer, args.lr * (args.gamma ** step_index))\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # The fix from our previous conversation\n",
    "                images, (targets, masks, num_crowds) = datum\n",
    "                images = torch.stack(images, 0)\n",
    "                \n",
    "                if args.cuda:\n",
    "                    # Logic for GPU would go here\n",
    "                    pass\n",
    "                else:\n",
    "                    losses = net(images, targets, masks, num_crowds)\n",
    "                \n",
    "                losses = { k: v.mean() for k, v in losses.items() }\n",
    "                loss = sum([losses[k] for k in losses])\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Logging\n",
    "                cur_time  = time.time()\n",
    "                elapsed   = cur_time - last_time\n",
    "                last_time = cur_time\n",
    "                time_avg.add(elapsed)\n",
    "                for k in losses:\n",
    "                    loss_avgs[k].add(losses[k].item())\n",
    "                \n",
    "                if iteration % 10 == 0:\n",
    "                    eta_str = str(datetime.timedelta(seconds=(cfg.max_iter-iteration) * time_avg.get_avg())).split('.')[0]\n",
    "                    total = sum([loss_avgs[k].get_avg() for k in losses])\n",
    "                    loss_labels = sum([[k, loss_avgs[k].get_avg()] for k in loss_types if k in losses], [])\n",
    "                    print(('[%3d] %7d ||' + (' %s: %.3f |' * len(losses)) + ' T: %.3f || ETA: %s || timer: %.3f')\n",
    "                            % tuple([epoch, iteration] + loss_labels + [total, eta_str, elapsed]), flush=True)\n",
    "\n",
    "                iteration += 1\n",
    "\n",
    "                if iteration % args.save_interval == 0 and iteration != 0:\n",
    "                    print('Saving state, iter:', iteration)\n",
    "                    yolact_net.save_weights(save_path(epoch, iteration))\n",
    "\n",
    "            if args.validation_epoch > 0:\n",
    "                if epoch % args.validation_epoch == 0 and epoch > 0:\n",
    "                    compute_validation_map(epoch, iteration, yolact_net, val_dataset, log if args.log else None)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print('Stopping early. Saving network...')\n",
    "        yolact_net.save_weights(save_path(epoch, repr(iteration) + '_interrupt'))\n",
    "    \n",
    "    yolact_net.save_weights(save_path(epoch, iteration))\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "# Start the training process\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
